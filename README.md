## **Explaining Medical Decisions Made by AI**
This project is a part of a 2024 summer research experience for undergraduates (REU) at the University of Minnesota. The REU's focus is human-centered computing for social good, and I am advised by Professor Qianwen Wang.
### Project description
Our research group is interested in studying how large language models (LLMs) respond differently to various medical-related inquiries. Specifically, we are studying the difference in how LLMs respond to medical inquiries formulated in a professional tone versus medical inquiries that are demographic-specific. The LLMs we will test are GPT and Llama 3. Our study will consist of feeding various types of medical-related questions into these LLMs in three stages. 
#### <ins>Stage 1</ins>
In the first stage, our input is a set of practice questions from the United States Medical Licensing Exam (USMLE). The USMLE is a three-step test that medical graduates must pass in order to become licensed medical professionals in the United States. The dataset contains over 10,000 questions from all three steps of the USMLE. We will feed these questions into GPT and Llama3 and record the LLMs' responses. Since the USMLE questions are considered professional medical questions, this stage of our research will serve as a metric of baseline LLM performance on standard medical inquiries.
#### <ins>Stage 2</ins>
In the second stage, our input is the same set of practice questions from the USMLE, but with added demographic information about race and income level for each patient. We chose to focus on race and income level because other relevant demographic factors, like age and gender, are already included in the original USMLE questions. We will feed these edited USMLE questions into GPT and Llama3 and record the LLMs' responses.
#### <ins>Stage 3</ins>
The third stage of our project has two sub-stages. First, we will feed a USMLE question into either GPT or Llama3 and ask the LLM to translate the question into the tone of a specific community. Additionally, we will provide examples of medical-related questions that real members of the specific community have asked to teach the LLM the appropriate tone and writing style to translate the USMLE questions into. For example, we will source some of these training questions from Reddit medical forums. Next, we will feed the LLM-translated questions into either GPT or Llama3 again and record each LLMs' response.
#### <ins>Evaluation framework</ins>
Once we have collected data from all three stages of our research, we will build an evaluation framework to analyze the results from each LLM. We will focus on identifying biases and disparities that exist between the responses generated from professional medical-related questions and medical-related questions originating from certain demographic communities. Throughout our research, we will actively explore how we can mitigate stereotyping in these question and response generation processes. 