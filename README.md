## ***Can I trust artificial intelligence with questions about my health?***
*Investigating the accuracy of AI-generated responses to simplified or demographic-specific medical questions.*
#### Project description and research questions
This project is part of a 2024 summer research experience for undergraduates (REU) at the University of Minnesota in Minneapolis, Minnesota. The REU's focus is human-centered computing for social good, and I am advised by Professor Qianwen Wang. Our research group is interested in studying how GPT-3.5, a prominent large language model (LLM), responds differently to various medical-related inquiries. Specifically, we are studying whether the widely recognized performance of GPT-3.5 on medical questions will decrease if questions are simplified or asked in unprofessional, realistic tones. If so, we are curious which factors make significant contributions to the decrease in performance. We tested the effect of both rephrasing medical questions in certain demographic tones (Reddit user, someone with no formal education, and non-Native English speaker) and altering medical questions to remove certain demographic factors (age and gender).
#### Motivation
The performance of GPT-3.5 has been tested extensively on professional medical questions from the United States Medical Licensing Exam (USMLE) and other similar datasets. However, GPT-3.5 has not been tested on simplified or unprofessional medical questions that are likely to come from everyday patients turning to AI platforms for advice about their health. Therefore, our research aims to investigate whether GPT-3.5 is equipped to appropriately respond to medical questions asked by patient groups not covered in current research.
#### Methods
We began by randomly sampling 50 questions from the USMLE dataset. We then fed each question into GPT-3.5 and asked the LLM to generate a new question based on the demographic tone or factor passed to the LLM in the prompt. After querying GPT-3.5 with this generated question, we recorded the LLM's response and asked GPT-3.5 to determine the accuracy of the response compared to the ground-truth answer provided by the USMLE dataset. This constituted one trial, and we completed ten trials with a unique subset of 50 medical questions for each trial. These steps were all executed by a Python script.